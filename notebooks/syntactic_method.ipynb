{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "input files for tests:\n",
        "\n",
        "skill test: https://drive.google.com/file/d/11orlLMoqsT_pZCJqa8MwhiDiaiGWf_xO/view?usp=sharing\n",
        "\n",
        "knowlede test: https://drive.google.com/file/d/1H5i0_3Qpazkfsli3TlAsE3mrALAW9SIv/view?usp=sharing\n",
        "\n",
        "note: to test with version 1 comment make_Ptree and algorithm1Ptree functions note: to test with version 2 comment algorithm1 function.\n",
        "note: to use 5-fold cross-validation uncomment one of fold 1 to fold 5 for each run.\n"
      ],
      "metadata": {
        "id": "1EysKoFUsU2u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cs4T5xeQQq1"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# 4 for making pattern trees, 1 for validation\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import networkx as nx\n",
        "from networkx.readwrite import json_graph\n",
        "with open('labeled_dataset_token_skill.json', 'r') as file:\n",
        "   data = json.load(file)\n",
        "\n",
        "new = defaultdict(list)\n",
        "for d in data:\n",
        "   new[d['sentence_id']].append(d)\n",
        "new_list = []\n",
        "\n",
        "for n, lst in new.items():\n",
        "    new_list.append(lst)\n",
        "train = new_list\n",
        "with open('labeled_dataset_token_dev.json', 'r') as file:\n",
        "   data = json.load(file)\n",
        "\n",
        "new = defaultdict(list)\n",
        "for d in data:\n",
        "   new[d['sentence_id']].append(d)\n",
        "new_list = []\n",
        "\n",
        "for n, lst in new.items():\n",
        "    new_list.append(lst)\n",
        "validation = new_list\n",
        "length_of_each_part = len(new_list) // 5\n",
        "# fold 1\n",
        "# train = new_list[:length_of_each_part*4]\n",
        "# validation = new_list[length_of_each_part*4:]\n",
        "# fold 2\n",
        "# train = new_list[:length_of_each_part*3]\n",
        "# validation = new_list[length_of_each_part*3:length_of_each_part*4]\n",
        "# train.extend(new_list[length_of_each_part*4:])\n",
        "# fold 3\n",
        "# train = new_list[:length_of_each_part*2]\n",
        "# validation = new_list[length_of_each_part*2:length_of_each_part*3]\n",
        "# train.extend(new_list[length_of_each_part*3:])\n",
        "# fold 4\n",
        "# train = new_list[:length_of_each_part]\n",
        "# validation = new_list[length_of_each_part:length_of_each_part*2]\n",
        "# train.extend(new_list[length_of_each_part*2:])\n",
        "# fold 5\n",
        "# validation = new_list[:length_of_each_part]\n",
        "# train = new_list[length_of_each_part:]\n",
        "\n",
        "def make_pattern_tree(train):\n",
        "    import networkx as nx\n",
        "    import json\n",
        "    from collections import defaultdict\n",
        "    from networkx.readwrite import json_graph\n",
        "\n",
        "    trees = []\n",
        "    for words in train:\n",
        "        def search(graph, property):\n",
        "            for node , data in graph.nodes(data = True):\n",
        "                if data.get('word_id') == property:\n",
        "                    return node\n",
        "\n",
        "        G1 = nx.DiGraph()\n",
        "        for i, word in enumerate(words,1):\n",
        "            G1.add_node(i, sentence_id=word['sentence_id'] , word_id=word['word_id'], text= word['text'].lower(), head = word['head'], deprel = word['deprel'], probability = word['probability'], children = word['children'], skill_tag = word['skill_tag'], skill_headword= word['skill_headword'])\n",
        "        for node, data in G1.nodes(data=True):\n",
        "            if data.get('head') > 0:\n",
        "                parent_node = search(G1, data.get('head'))\n",
        "                G1.add_edge(parent_node, node, weight = data.get('probability'))\n",
        "        trees.append(G1)\n",
        "\n",
        "    headword_trees = []\n",
        "    for tree in trees:\n",
        "        for node in tree.nodes(data = True):\n",
        "            if node[1].get('skill_headword') == True:\n",
        "                parent = list(tree.predecessors(node[0]))\n",
        "                if parent == []:\n",
        "                    headword_trees.append(tree)\n",
        "                    continue\n",
        "                temp = tree.copy()\n",
        "                temp.remove_edge(parent[0], node[0])\n",
        "                components = list(nx.weakly_connected_components(temp))\n",
        "                subgraphs = [temp.subgraph(component).copy() for component in components]\n",
        "                headword_trees.append(subgraphs[1])\n",
        "\n",
        "    # merging headword trees\n",
        "    def save_trees_to_file(trees, filename):\n",
        "        data = []\n",
        "        for tree in trees:\n",
        "            tree_data = json_graph.node_link_data(tree)\n",
        "            data.append(tree_data)\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(data, f, indent=4)\n",
        "\n",
        "    def find_root(graph):\n",
        "        for node in graph.nodes:\n",
        "            if graph.in_degree(node) == 0:\n",
        "                return node\n",
        "        return None\n",
        "\n",
        "    def relabeling(graph1,graph2):\n",
        "        offset = max(graph1.nodes) + 1\n",
        "        graph2 = nx.relabel_nodes(graph2, lambda x: x + offset)\n",
        "        return graph2\n",
        "\n",
        "    def merge_graphs(graph_list):\n",
        "        if not graph_list:\n",
        "            return None\n",
        "        merged_graph = nx.DiGraph()\n",
        "        new = []\n",
        "        stack = []\n",
        "        new.append(graph_list[0])\n",
        "\n",
        "        for i in graph_list:\n",
        "            if not graph_list.index(i)+1 == len(graph_list):\n",
        "                if stack == []:\n",
        "                    x = relabeling(i, graph_list[graph_list.index(i)+1])\n",
        "                    graph_list[graph_list.index(i)] = x\n",
        "                    new.append(x)\n",
        "                    stack.append(x)\n",
        "                else:\n",
        "                    x = relabeling(stack.pop(), graph_list[graph_list.index(i)+1])\n",
        "                    new.append(x)\n",
        "                    stack.append(x)\n",
        "\n",
        "        for graph in new:\n",
        "            merged_graph = nx.compose(merged_graph, graph)\n",
        "\n",
        "        roots = []\n",
        "        for node in merged_graph.nodes:\n",
        "            parent = list(merged_graph.predecessors(node))\n",
        "            if parent == []:\n",
        "                roots.append(node)\n",
        "        children = []\n",
        "        for root in roots[1:]:\n",
        "            children.extend(list(merged_graph.successors(root)))\n",
        "\n",
        "        for child in children:\n",
        "            weight = merged_graph.nodes[child].get('probability')\n",
        "            merged_graph.add_edge(roots[0],child ,weight = weight)\n",
        "        for root in roots[1:]:\n",
        "            merged_graph.remove_node(root)\n",
        "\n",
        "\n",
        "        return merged_graph\n",
        "\n",
        "    # Group trees by their root 'text' property\n",
        "    trees_by_root_text = defaultdict(list)\n",
        "\n",
        "    for tree in headword_trees:\n",
        "        root = find_root(tree)\n",
        "        if root is not None:\n",
        "            root_text = tree.nodes[root]['text'].lower()\n",
        "            trees_by_root_text[root_text].append(tree)\n",
        "\n",
        "    # Merge trees with the same root 'text'\n",
        "    pattern_trees = []\n",
        "\n",
        "    for root_text, tree_group in trees_by_root_text.items():\n",
        "        merged_tree = merge_graphs(tree_group)\n",
        "        if merged_tree is not None:\n",
        "            pattern_trees.append(merged_tree)\n",
        "\n",
        "    return(pattern_trees)\n",
        "\n",
        "pattern_trees = make_pattern_tree(train)\n",
        "\n",
        "# def make_Ptree(pattern_trees):\n",
        "#     def find_root(graph):\n",
        "#         for node in graph.nodes:\n",
        "#             if graph.in_degree(node) == 0:\n",
        "#                 return node\n",
        "#         return None\n",
        "#     P_trees = []\n",
        "#     for tree in pattern_trees:\n",
        "\n",
        "#         G1 = nx.DiGraph()\n",
        "#         def make_pattern_tree_root(node,nodeid):\n",
        "#             temp = defaultdict(lambda: [0, 0])\n",
        "\n",
        "#             children = list(tree.successors(node))\n",
        "#             # print(len(children))\n",
        "#             for child in children:\n",
        "#                 dep = tree.nodes(data = True)[child]['deprel']\n",
        "#                 tag = tree.nodes(data = True)[child]['skill_tag']\n",
        "#                 temp[dep][0] += 1\n",
        "#                 if tag == 'B' or tag == 'I':\n",
        "#                     temp[dep][1]+=1\n",
        "#             final = {}\n",
        "#             for depen, tup in temp.items():\n",
        "#                     if tup[1] != 0:\n",
        "#                         final[depen] = tup[1]/tup[0]\n",
        "#             root_node = nodeid\n",
        "#             for dep, weight in final.items():\n",
        "#                 G1.add_node(nodeid+1, name= dep, freq = weight)\n",
        "#                 G1.add_edge(root_node,nodeid+1)\n",
        "#                 nodeid+=1\n",
        "#             # for child in children:\n",
        "#                 # make_pattern_tree(child, nodeid)\n",
        "#             return nodeid\n",
        "\n",
        "\n",
        "\n",
        "#         root = find_root(tree)\n",
        "#         name1 = tree.nodes(data = True)[root]['text']\n",
        "\n",
        "#         G1.add_node(1, name = name1)\n",
        "\n",
        "#         next_node = make_pattern_tree_root(root,1) + 1\n",
        "\n",
        "#         leaf_nodes = [n for n, d in tree.out_degree() if d == 0]\n",
        "#         all_paths = []\n",
        "#         for leaf in leaf_nodes:\n",
        "#             paths = list(nx.all_simple_paths(tree, root, leaf))\n",
        "#             all_paths.extend(paths)\n",
        "#         all_paths_names = [[tree.nodes[node]['deprel'] for node in path] for path in all_paths]\n",
        "#         for path in all_paths_names:\n",
        "#             path[0] = 'root'\n",
        "\n",
        "#         def similar_lists(list1,list2,level):\n",
        "#             for i in range(level):\n",
        "#                 if list1[i] != list2[i]:\n",
        "#                     return False\n",
        "\n",
        "#             return True\n",
        "#         stat = True\n",
        "#         children = ['a']\n",
        "#         leaf_nodess = []\n",
        "#         while stat:\n",
        "#             if leaf_nodess == []:\n",
        "#                 leaf_nodess = [n for n, d in G1.out_degree() if d == 0]\n",
        "#             else:\n",
        "#                 if leaf_nodess == [n for n, d in G1.out_degree() if d == 0]:\n",
        "#                     stat = False\n",
        "#                 else:\n",
        "#                     leaf_nodess = [n for n, d in G1.out_degree() if d == 0]\n",
        "#             all_pathss = []\n",
        "#             for leaf in leaf_nodess:\n",
        "#                 paths = list(nx.all_simple_paths(G1, 1, leaf))\n",
        "#                 all_pathss.extend(paths)\n",
        "#             # all_paths_namess = [[G1.nodes[node]['name'] for node in path] for path in all_pathss]\n",
        "#             all_paths_namess = []\n",
        "#             for p in all_pathss:\n",
        "#                 temp = []\n",
        "#                 for i in p:\n",
        "#                     temp.append(G1.nodes[i]['name'])\n",
        "#                 all_paths_namess.append(temp)\n",
        "#             # print('*'+ str(len(all_paths_namess)))\n",
        "#             for path in all_paths_namess:\n",
        "#                 path[0] = 'root'\n",
        "#             for path in all_paths_namess:\n",
        "#                 level = len(path) - 1\n",
        "#                 pathsx = nx.single_source_shortest_path_length(tree, root)\n",
        "#                 nodes_at_level = [node for node, distance in pathsx.items() if distance == level]\n",
        "#                 children = []\n",
        "#                 for node in nodes_at_level:\n",
        "#                     children.extend(list(tree.successors(node)))\n",
        "#                 if children == []:\n",
        "#                     stat = False\n",
        "#                 # print('**'+str(len(nodes_at_level)))\n",
        "#                 # print(children)\n",
        "#                 children_dep = []\n",
        "#                 for child in children:\n",
        "#                     dep_name = tree.nodes[child]['deprel']\n",
        "#                     if dep_name not in children_dep:\n",
        "#                         children_dep.append(dep_name)\n",
        "\n",
        "#                 test_paths = []\n",
        "#                 for i in range(len(children_dep)):\n",
        "#                     test_paths.append( path.copy() + [children_dep[i]])\n",
        "#                 compare_res = defaultdict(lambda: [0, 0])\n",
        "#                 # print(test_paths)\n",
        "#                 for tree_path in all_paths_names:\n",
        "#                     if len(tree_path) >= level+2:\n",
        "#                         for test_path in test_paths:\n",
        "#                             res = similar_lists(tree_path,test_path,level+2)\n",
        "#                             if res:\n",
        "#                                 compare_res[test_path[level+1]][0] += 1\n",
        "#                                 x = all_paths[all_paths_names.index(tree_path)][level+1]\n",
        "#                                 tag = tree.nodes[x]['skill_tag']\n",
        "#                                 if tag== 'B'or tag == 'I':\n",
        "#                                     compare_res[test_path[level+1]][1] += 1\n",
        "#                 # print(compare_res)\n",
        "#                 # making the tree\n",
        "#                 parent = all_pathss[all_paths_namess.index(path)][-1]\n",
        "#                 for dep, tup in compare_res.items():\n",
        "#                     if tup[1] != 0:\n",
        "#                         weight = tup[1]/tup[0]\n",
        "#                         G1.add_node(next_node, name= dep, freq = weight)\n",
        "#                         G1.add_edge(parent,next_node)\n",
        "#                         next_node +=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         P_trees.append(G1)\n",
        "#     return P_trees\n",
        "\n",
        "# P_trees = make_Ptree(pattern_trees)\n",
        "\n",
        "def algorithm1(H):\n",
        "    def find_root(graph):\n",
        "        for node in graph.nodes:\n",
        "            if graph.in_degree(node) == 0:\n",
        "                return node\n",
        "        return None\n",
        "    with open('index_v2.json', 'r') as file:\n",
        "        I = json.load(file)\n",
        "\n",
        "    T = {}\n",
        "    for term, value in I.items():\n",
        "        T[term] = 0\n",
        "\n",
        "    def TreeSearch(i, tup_list, D, id, t):\n",
        "        for tup in tup_list:\n",
        "            t_prim = tup[0]\n",
        "            d = tup[1]\n",
        "\n",
        "            for m in list(D.successors(id)):\n",
        "                if D.nodes[m].get('deprel') == d:\n",
        "                    w = D.get_edge_data(id, m)['weight']\n",
        "                    T[t_prim] += w\n",
        "                    tag = D.nodes[m].get('skill_tag')\n",
        "                    children = I.get(t_prim)[0].index(i)\n",
        "                    TreeSearch(i ,I.get(t_prim)[1][children] ,D ,m, t_prim)\n",
        "\n",
        "\n",
        "\n",
        "    for h in H:\n",
        "        identifier = find_root(h)\n",
        "        word = h.nodes[identifier].get('text')\n",
        "        res = I.get(word)\n",
        "        if res:\n",
        "            for i,dependency in zip(res[0],res[1]):\n",
        "                TreeSearch(i,dependency, h, identifier, word)\n",
        "\n",
        "    # for T v2\n",
        "    for t, score in T.items():\n",
        "        len_t = len(I.get(t)[0])\n",
        "        score = round(score / len_t, 4)\n",
        "        T[t] = score\n",
        "\n",
        "    return T\n",
        "\n",
        "T = algorithm1(pattern_trees)\n",
        "\n",
        "# def algorithm1Ptree(H):\n",
        "#     def find_root(graph):\n",
        "#         for node in graph.nodes:\n",
        "#             if graph.in_degree(node) == 0:\n",
        "#                 return node\n",
        "#         return None\n",
        "#     with open('index_v2.json', 'r') as file:\n",
        "#         I = json.load(file)\n",
        "\n",
        "#     T = {}\n",
        "#     for term, value in I.items():\n",
        "#         T[term] = 0\n",
        "\n",
        "#     def TreeSearch(i, tup_list, D, id, t):\n",
        "#       for tup in tup_list:\n",
        "#         t_prim = tup[0]\n",
        "#         d = tup[1]\n",
        "\n",
        "#         for m in list(D.successors(id)):\n",
        "#            if D.nodes[m].get('name') == d:\n",
        "#               w = D.nodes[m].get('freq')\n",
        "#               T[t_prim] += w\n",
        "#               children = I.get(t_prim)[0].index(i)\n",
        "#               TreeSearch(i ,I.get(t_prim)[1][children] ,D ,m, t_prim)\n",
        "\n",
        "\n",
        "\n",
        "#     for h in H:\n",
        "#         identifier = find_root(h)\n",
        "#         word = h.nodes[identifier].get('name')\n",
        "#         res = I.get(word)\n",
        "#         if res:\n",
        "#             for i,dependency in zip(res[0],res[1]):\n",
        "#                 TreeSearch(i,dependency, h, identifier, word)\n",
        "\n",
        "#     # for T v2\n",
        "#     for t, score in T.items():\n",
        "#         len_t = len(I.get(t)[0])\n",
        "#         score = round(score / len_t, 4)\n",
        "#         T[t] = score\n",
        "#     return T\n",
        "\n",
        "# T = algorithm1Ptree(P_trees)\n",
        "\n",
        "def make_new_validation(validation):\n",
        "    words_not_in_T = 0\n",
        "    words_in_T = 0\n",
        "    new_validation= defaultdict(list)\n",
        "\n",
        "    for items in validation:\n",
        "        for item in items:\n",
        "            if item['text'] in T.keys():\n",
        "                score = T[item['text']]\n",
        "                item['score'] = score\n",
        "                new_validation[str(item['sentence_id'])].append(item)\n",
        "                words_in_T +=1\n",
        "            else:\n",
        "                words_not_in_T +=1\n",
        "\n",
        "    # print(words_in_T) # 6435\n",
        "    print('number of missed word in validation: '+ str(words_not_in_T)) # 470\n",
        "    return new_validation\n",
        "\n",
        "validation = make_new_validation(validation)\n",
        "\n",
        "# %%\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def group_terms(terms, window_size):\n",
        "    grouped_terms = []\n",
        "    for i, term in enumerate(terms):\n",
        "        if term['text'] == '.':\n",
        "            continue\n",
        "\n",
        "        temp = []\n",
        "        tags = []\n",
        "        scores = 0\n",
        "        temp.append(terms[i]['text'])\n",
        "        tags.append(terms[i]['skill_tag'])\n",
        "        scores += terms[i]['score']\n",
        "        for j in range(1, window_size):\n",
        "            if i + j < len(terms):\n",
        "                if terms[i + j]['text']== '.':\n",
        "                    continue\n",
        "                temp.append(terms[i + j]['text'])\n",
        "                tags.append(terms[i+j]['skill_tag'])\n",
        "                scores += terms[i+j]['score']\n",
        "        if len(temp) == window_size:\n",
        "            grouped_terms.append({'phrase': temp, 'tags': tags, 'score': scores/len(temp)})\n",
        "\n",
        "    return grouped_terms\n",
        "\n",
        "x = defaultdict(list)\n",
        "for sent,words in validation.items():\n",
        "\n",
        "   for i in range(2,6):\n",
        "      grouped_terms = group_terms(words, i)\n",
        "      x[sent].extend(grouped_terms)\n",
        "\n",
        "# print(x['1'])\n",
        "\n",
        "# validation test 2 - phrase test\n",
        "\n",
        "new = []\n",
        "\n",
        "for i,j in x.items():\n",
        "    for b in j:\n",
        "        if not ('O'in b['tags'] and 'B' in b['tags']):\n",
        "            if not ('O' in b['tags'] and 'I' in b['tags']):\n",
        "                # print(b)\n",
        "                new.append(b)\n",
        "max_f1 = 0\n",
        "phrase_max_score = 0\n",
        "sorted_list_desc = sorted(new, key=lambda a: a['score'], reverse=True)\n",
        "sum_skill = 0\n",
        "number_skill = 0\n",
        "sum_non_skill = 0\n",
        "number_non_skill = 0\n",
        "\n",
        "for i in sorted_list_desc:\n",
        "    if 'O' in i['tags']:\n",
        "        sum_non_skill += i['score']\n",
        "        number_non_skill += 1\n",
        "    else:\n",
        "        sum_skill += i['score']\n",
        "        number_skill +=1\n",
        "\n",
        "skill_word_average_score = sum_skill/number_skill\n",
        "non_skill_word_average_score = sum_non_skill/number_non_skill\n",
        "print('average score for positive label phrases: ' + str(skill_word_average_score)) # 0.2036031954117182\n",
        "print('average score for negative label phrases: ' + str(non_skill_word_average_score)) # 0.10644162035683126\n",
        "var_d_p = 0\n",
        "var_d_n = 0\n",
        "for i in sorted_list_desc:\n",
        "    if 'O' in i['tags']:\n",
        "        var_d_n += (i['score'] - non_skill_word_average_score)*(i['score'] - non_skill_word_average_score)\n",
        "    else:\n",
        "        var_d_p += (i['score'] - skill_word_average_score)*(i['score'] - skill_word_average_score)\n",
        "var_p = var_d_p/sum_skill\n",
        "var_n = var_d_n/sum_non_skill\n",
        "print('variance of positive labeled phrases: ' + str(var_p))\n",
        "print('variance of negative labeled phrases: ' + str(var_n))\n",
        "# print((skill_word_average_score-non_skill_word_average_score)*(skill_word_average_score-non_skill_word_average_score)/(var_n+var_p))\n",
        "relevant = 0\n",
        "for entry in sorted_list_desc:\n",
        "        if 'I'in entry['tags'] or 'B'in entry['tags']:\n",
        "            relevant += 1\n",
        "retrieved = 0\n",
        "relevant_retrieved = 0\n",
        "# uncomment if you want to see precision at 10 percent to 100 percent recall for phrase test\n",
        "# for x in sorted_list_desc:\n",
        "#     if not('O' in x['tags']):\n",
        "#         relevant_retrieved +=1\n",
        "#     if relevant_retrieved == relevant//10*1 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('10')\n",
        "#         print(relevant*0.1/retrieved)\n",
        "#         print(retrieved)\n",
        "#         print(relevant//10*1)\n",
        "#     if relevant_retrieved == relevant//10*2 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('20')\n",
        "#         print(relevant*0.2/retrieved)\n",
        "#         print(retrieved)\n",
        "#     if relevant_retrieved == relevant//10*3 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('30')\n",
        "#         print(relevant*0.3/retrieved)\n",
        "#         print(retrieved)\n",
        "#     if relevant_retrieved == relevant//10*4 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('40')\n",
        "#         print(relevant*0.4/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*5 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('50')\n",
        "#         print(relevant*0.5/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*6 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('60')\n",
        "#         print(relevant*0.6/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*7 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('70')\n",
        "#         print(relevant*0.7/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*8 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('80')\n",
        "#         print(relevant*0.8/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*9 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('90')\n",
        "#         print(relevant*0.9/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*10 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('100')\n",
        "#         print(relevant*1/retrieved)\n",
        "#         print(retrieved)\n",
        "\n",
        "# for ph in sorted_list_desc:\n",
        "#         if ph['score'] > phrase_max_score:\n",
        "#             phrase_max_score = ph['score']\n",
        "#         if not('O' in ph['tags']):\n",
        "#             if ph['score'] >= th:\n",
        "#                 true_positive +=1\n",
        "#             if ph['score'] < th:\n",
        "#                 false_negative +=1\n",
        "#         if 'O' in ph['tags']:\n",
        "#             if ph['score'] >= th:\n",
        "#                 false_positive +=1\n",
        "#             if  ph['score'] < th:\n",
        "#                 true_negative +=1\n",
        "#     precision = round( true_positive/(true_positive+false_positive),4)\n",
        "#     recall = round(true_positive/(true_positive+false_negative),4)\n",
        "#     f1 = 2*(precision*recall)/(precision+recall)\n",
        "# print(phrase_max_score)\n",
        "\n",
        "max_f1 = 0\n",
        "max_th = 0\n",
        "start = 0\n",
        "for num in np.arange(0, 2.5, 0.01):\n",
        "    true_positive =0\n",
        "    true_negative =0\n",
        "    false_positive = 0\n",
        "    false_negative =0\n",
        "    for ph in sorted_list_desc:\n",
        "        if not('O' in ph['tags']):\n",
        "            if ph['score'] >= num:\n",
        "                true_positive +=1\n",
        "            if ph['score'] < num:\n",
        "                false_negative +=1\n",
        "        if 'O' in ph['tags']:\n",
        "            if ph['score'] >= num:\n",
        "                false_positive +=1\n",
        "            if  ph['score'] < num:\n",
        "                true_negative +=1\n",
        "    if true_positive == 0 and false_positive == 0:\n",
        "        continue\n",
        "    if false_negative == 0 and true_positive== 0 :\n",
        "        continue\n",
        "    precision = round( true_positive/(true_positive+false_positive),4)\n",
        "    recall = round(true_positive/(true_positive+false_negative),4)\n",
        "    if precision==0 or recall==0:\n",
        "        continue\n",
        "    f1 = 2*(precision*recall)/(precision+recall)\n",
        "\n",
        "    if f1 > max_f1:\n",
        "        max_f1 = f1\n",
        "        max_th = num\n",
        "    if num == 0.04:\n",
        "        print('0.04 '+str(f1))\n",
        "    if num == 0.24:\n",
        "        print('0.24 '+str(f1))\n",
        "    if num == 0.36:\n",
        "        print('0.36 '+ str(f1))\n",
        "    if num == 0.19:\n",
        "        print('0.19 '+ str(f1))\n",
        "    if num == 0.17:\n",
        "        print('0.17 '+ str(f1))\n",
        "print('max f1 '+ str(max_f1))\n",
        "print('max th '+ str(max_th))\n",
        "\n",
        "# single word test\n",
        "true_positive =0\n",
        "true_positive_ls = []\n",
        "true_negative =0\n",
        "false_positive = 0\n",
        "false_negative =0\n",
        "false_negative_ls = []\n",
        "max_score = 0\n",
        "# threshold = round(max_score/2, 2)\n",
        "sinle_max_f1 = 0\n",
        "single_max_th = 0\n",
        "for th in np.arange(0, 2.0, 0.01):\n",
        "\n",
        "    for entry,items in validation.items():\n",
        "        for item in items:\n",
        "            if item['score'] > max_score:\n",
        "                max_score = item['score']\n",
        "            tag = item['skill_tag']\n",
        "            score = item['score']\n",
        "            if ((tag == 'I' or tag == 'B') and score >= th) :\n",
        "                true_positive +=1\n",
        "                true_positive_ls.append(item)\n",
        "            if ((tag == 'I' or tag == 'B') and score < th) :\n",
        "                false_negative +=1\n",
        "                false_negative_ls.append(item)\n",
        "            if ((tag == 'O') and score < th) :\n",
        "                true_negative +=1\n",
        "            if ((tag == 'O') and score >= th) :\n",
        "                false_positive +=1\n",
        "\n",
        "    precision = round( true_positive/(true_positive+false_positive),4)\n",
        "    recall = round(true_positive/(true_positive+false_negative),4)\n",
        "    f1 = 2*(precision*recall)/(precision+recall)\n",
        "    if f1 > sinle_max_f1:\n",
        "        sinle_max_f1 = f1\n",
        "        single_max_th = th\n",
        "    if th == 0.28 :\n",
        "        print('0.28 '+str(f1))\n",
        "    if th == 0.3:\n",
        "        print('0.3 '+str(f1))\n",
        "    if th == 0.38:\n",
        "        print('0.38 '+str(f1))\n",
        "    if th == 0.17:\n",
        "        print('0.17 '+str(f1))\n",
        "print('f1 '+ str(sinle_max_f1))\n",
        "print('th '+str(single_max_th))\n",
        "print()\n",
        "# print(str(precision))\n",
        "# print(str(recall))\n",
        "# print(str(true_positive))\n",
        "# print(str(false_positive))\n",
        "# print(str(false_negative))\n",
        "# print(str(true_negative))\n",
        "# print(str(max_score))\n",
        "# print(true_positive_ls)\n",
        "# print(false_negative_ls)\n",
        "\n",
        "relevant = 0\n",
        "for entry,items in validation.items():\n",
        "    for item in items:\n",
        "        tag = item['skill_tag']\n",
        "        if tag == 'B' or tag == 'I':\n",
        "            relevant +=1\n",
        "print(relevant)\n",
        "print(relevant*0.1) # 244\n",
        "\n",
        "new = []\n",
        "for i,j in validation.items():\n",
        "    for x in j:\n",
        "        new.append(x)\n",
        "sorted_list_desc = sorted(new, key=lambda x: x['score'], reverse=True)\n",
        "retrieved = 0\n",
        "relevant_retrieved = 0\n",
        "# uncomment this part if wnat to see precision from 10 to 100 percent of recall\n",
        "# for x in sorted_list_desc:\n",
        "#     if x['skill_tag'] == 'B' or x['skill_tag'] == 'I':\n",
        "#         relevant_retrieved +=1\n",
        "#     if relevant_retrieved == relevant//10*1 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('10')\n",
        "#         print(relevant*0.1/retrieved)\n",
        "#         print(retrieved)\n",
        "#         print(relevant//10*1)\n",
        "#     if relevant_retrieved == relevant//10*2 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('20')\n",
        "#         print(relevant*0.2/retrieved)\n",
        "#         print(retrieved)\n",
        "#     if relevant_retrieved == relevant//10*3 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('30')\n",
        "#         print(relevant*0.3/retrieved)\n",
        "#         print(retrieved)\n",
        "#     if relevant_retrieved == relevant//10*4 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('40')\n",
        "#         print(relevant*0.4/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*5 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('50')\n",
        "#         print(relevant*0.5/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*6 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('60')\n",
        "#         print(relevant*0.6/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*7 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('70')\n",
        "#         print(relevant*0.7/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*8 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('80')\n",
        "#         print(relevant*0.8/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*9 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('90')\n",
        "#         print(relevant*0.9/retrieved)\n",
        "#     if relevant_retrieved == relevant//10*10 :\n",
        "#         retrieved = sorted_list_desc.index(x)+1\n",
        "#         print('100')\n",
        "#         print(relevant*1/retrieved)\n",
        "#         print(retrieved)\n",
        "\n",
        "sum_skill = 0\n",
        "number_skill = 0\n",
        "sum_non_skill = 0\n",
        "number_non_skill = 0\n",
        "for i in sorted_list_desc:\n",
        "    if i['skill_tag'] == 'I' or i['skill_tag'] == 'B':\n",
        "        sum_skill += i['score']\n",
        "        number_skill +=1\n",
        "    else:\n",
        "        sum_non_skill += i['score']\n",
        "        number_non_skill += 1\n",
        "\n",
        "skill_word_average_score = sum_skill/number_skill\n",
        "non_skill_word_average_score = sum_non_skill/number_non_skill\n",
        "print('average score for positive label phrases: '+ str(skill_word_average_score)) # 0.2036031954117182\n",
        "print('average score for negative label phrases: '+ str(non_skill_word_average_score)) # 0.10644162035683126\n",
        "var_d_p = 0\n",
        "var_d_n = 0\n",
        "for i in sorted_list_desc:\n",
        "    if i['skill_tag'] == 'I' or i['skill_tag'] == 'B':\n",
        "        var_d_p += (i['score'] - skill_word_average_score)*(i['score'] - skill_word_average_score)\n",
        "    else:\n",
        "        var_d_n += (i['score'] - non_skill_word_average_score)*(i['score'] - non_skill_word_average_score)\n",
        "var_p = var_d_p/sum_skill\n",
        "var_n = var_d_n/sum_non_skill\n",
        "print('variance of positive labeled words: '+ str(var_p))\n",
        "print('variance of negative labeled words: '+ str(var_n))\n",
        "# print((skill_word_average_score-non_skill_word_average_score)*(skill_word_average_score-non_skill_word_average_score)/(var_n+var_p))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "making parsed information from SkillSpan dataset.\n"
      ],
      "metadata": {
        "id": "iq4cChkM017j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "\n",
        "# stanza.download('en', download_method=None)\n",
        "\n",
        "import json\n",
        "with open('test.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract the 'tokens' values from each entry in the JSON data\n",
        "tokens_list = [entry['tokens'] for entry in data]\n",
        "print(len(tokens_list))\n",
        "tag_skill_list = [entry['tags_skill'] for entry in data]\n",
        "tag_knowledge_list = [entry['tags_knowledge'] for entry in data]\n",
        "\n",
        "stanza_input = []\n",
        "stanza_skill_tags = []\n",
        "# stanza_knowledge_tags =[]\n",
        "for i in range(0,3569):\n",
        "  if \"B\" in tag_skill_list[i]:# or \"B\" in tag_knowledge_list[i]:\n",
        "    stanza_input.append(tokens_list[i])\n",
        "    stanza_skill_tags.append(tag_skill_list[i])\n",
        "    # stanza_knowledge_tags.append(tag_knowledge_list[i])\n",
        "print(len(stanza_input))\n",
        "print(len(stanza_skill_tags))\n",
        "\n",
        "# Define a custom Word class with additional custom properties\n",
        "class MyWord:\n",
        "    def __init__(self, text, lemma, pos, custom_property=None):\n",
        "        self.text = text\n",
        "        self.lemma = lemma\n",
        "        self.pos = pos\n",
        "        self.skill_tag = custom_property\n",
        "        self.knowledge_tag = custom_property\n",
        "        self.children = []\n",
        "\n",
        "    def add_child(self, child_node):\n",
        "        self.children.append(child_node)\n",
        "\n",
        "\n",
        "# Override the word_class argument to use your custom Word class\n",
        "nlp = stanza.Pipeline('en', tokenize_pretokenized=True, word_class=MyWord, processors='tokenize,mwt,pos,lemma,depparse', download_method=None)\n",
        "\n",
        "# Process a sentence\n",
        "doc = nlp(stanza_input)\n",
        "\n",
        "print(len(doc.sentences))\n",
        "# Set a custom property for each word\n",
        "for j, sent in enumerate(doc.sentences):\n",
        "  for i, word in enumerate(doc.sentences[j].words):\n",
        "    word.skill_tag = stanza_skill_tags[j][i]\n",
        "\n",
        "print(doc.sentences[0].words)\n",
        "\n",
        "head_words = []\n",
        "head_word_object = []\n",
        "for j, sent in enumerate(doc.sentences):\n",
        "  for i, word in enumerate(doc.sentences[j].words):\n",
        "    word.sentence_id = j\n",
        "    word.skill_headword = False\n",
        "    if word.skill_tag == \"B\" and word.head != 0 :\n",
        "      x= doc.sentences[j].words[word.head - 1]\n",
        "      if x.skill_tag == \"O\":\n",
        "        head_words.append({'word':x.text, 'sentence id': j, 'word id': x.id})\n",
        "        head_word_object.append(x)\n",
        "        x.skill_headword = True\n",
        "\n",
        "      else:\n",
        "        while x.skill_tag != \"O\" and x.head != 0 :\n",
        "          x = doc.sentences[j].words[x.head - 1]\n",
        "        if x.skill_tag == \"O\":\n",
        "          head_words.append({'word':x.text, 'sentence id': j, 'word id': x.id})\n",
        "          head_word_object.append(x)\n",
        "          x.skill_headword = True\n",
        "\n",
        "# %%\n",
        "# add children\n",
        "roots =[]\n",
        "\n",
        "for j, sent in enumerate(doc.sentences):\n",
        "    children_dict = {word.id: [] for word in sent.words}\n",
        "    children_dict_word = {word.id: [] for word in sent.words}\n",
        "    for word in sent.words:\n",
        "        head_id = word.head\n",
        "        if head_id == 0:\n",
        "           roots.append(word.id)\n",
        "        if head_id > 0:  # Head id of 0 means it's the root\n",
        "            children_dict_word[head_id].append(word)\n",
        "            children_dict[head_id].append(word.id)\n",
        "\n",
        "\n",
        "    # Add the children property to each word\n",
        "    for word in sent.words:\n",
        "        word.children_word = children_dict_word[word.id]\n",
        "        word.children = children_dict[word.id]\n",
        "\n",
        "\n",
        "    # Print out the word details with the custom property\n",
        "    for word in sent.words:\n",
        "        print(f\"Word: {word.text}, ID: {word.id}, Head: {word.head}, Children: {word.children}\")\n",
        "\n",
        "# add freq.\n",
        "\n",
        "# formula for freq = number of all nodes with B or I tags in subtree of an edge / number of all nodes with B or I tages in e level higher + 1\n",
        "# the denominator + 1 is for avoiding freq. to become 1\n",
        "\n",
        "\n",
        "for j, sent in enumerate(doc.sentences):\n",
        "\n",
        "\n",
        "  def dfs_postorder(root):\n",
        "    if root:\n",
        "        for child in root.children_word:\n",
        "            # print(child)\n",
        "            dfs_postorder(child)\n",
        "        print(str(root.id) + \"->\", end='')\n",
        "        if not root.children_word:\n",
        "          root.freq = (root.skill_tag == \"B\" or root.skill_tag == \"I\") + 0\n",
        "        else:\n",
        "           freq1 = 0\n",
        "           for child in root.children_word:\n",
        "              freq1 += child.freq\n",
        "           freq1 += (root.skill_tag == \"B\" or root.skill_tag == \"I\")\n",
        "           root.freq = freq1\n",
        "\n",
        "  def probabilityCount(root):\n",
        "     if root.head == 0:\n",
        "        root.prob = 0\n",
        "     else:\n",
        "        parent = sent.words[root.head-1]\n",
        "        p_freq = parent.freq - (parent.skill_tag == \"B\" or parent.skill_tag == \"I\")\n",
        "        root.prob = root.freq / (p_freq + 1)\n",
        "     for child in root.children_word:\n",
        "        probabilityCount(child)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  root = sent.words[roots[j]-1]\n",
        "  dfs_postorder(root)\n",
        "  probabilityCount(root)\n",
        "\n",
        "combined_data = []\n",
        "for j, sent in enumerate(doc.sentences):\n",
        "   for word in sent.words:\n",
        "                info = {\n",
        "                    'sentence_id': j,\n",
        "                    'word_id': word.id,\n",
        "                    'text': word.text.lower(),\n",
        "                    'lemma': word.lemma,\n",
        "                    'upos': word.upos,\n",
        "                    'xpos': word.xpos,\n",
        "                    'head': word.head,\n",
        "                    'deprel': word.deprel,\n",
        "                    'probability': word.prob,\n",
        "                    'children': word.children,\n",
        "                    'skill_tag': word.skill_tag,\n",
        "                    'skill_headword': word.skill_headword\n",
        "\n",
        "                }\n",
        "                combined_data.append(info)\n",
        "\n",
        "with open('labeled_dataset_token_skill.json', 'w') as f:\n",
        "    json.dump(combined_data, f, indent=4)"
      ],
      "metadata": {
        "id": "1ZJRfFbL0rj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}